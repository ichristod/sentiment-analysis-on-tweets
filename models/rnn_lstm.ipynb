{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e64a5327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>original_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128037</th>\n",
       "      <td>0</td>\n",
       "      <td>Oh really don't wanna be awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491755</th>\n",
       "      <td>0</td>\n",
       "      <td>Trying to amuse my cousin. It's not working! a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470924</th>\n",
       "      <td>0</td>\n",
       "      <td>@JonasAustralia  i wanted to win! congrats to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491263</th>\n",
       "      <td>0</td>\n",
       "      <td>That's it!! I can't take it no more!! After su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836489</th>\n",
       "      <td>4</td>\n",
       "      <td>@beckybootsx i hope your not drinking alcohol!...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentiment                                    original_tweets\n",
       "128037          0                    Oh really don't wanna be awake \n",
       "491755          0  Trying to amuse my cousin. It's not working! a...\n",
       "470924          0  @JonasAustralia  i wanted to win! congrats to ...\n",
       "491263          0  That's it!! I can't take it no more!! After su...\n",
       "836489          4  @beckybootsx i hope your not drinking alcohol!..."
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from nltk.corpus import stopwords \n",
    "import pandas as pd\n",
    "import numpy as  np\n",
    "import matplotlib as plt\n",
    "import re\n",
    "import string\n",
    "\n",
    "#jupyter path\n",
    "cols = ['sentiment','id','date','query_string','user','original_tweets']\n",
    "df_encoding = \"ISO-8859-1\"\n",
    "df = pd.read_csv(\"training.1600000.processed.noemoticon.csv\",encoding =df_encoding, header=None, names=cols)\n",
    "df.drop(['id','date','query_string','user'],axis=1,inplace=True)\n",
    "df = df.sample(frac=0.05, replace=True, random_state=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f25c62",
   "metadata": {},
   "source": [
    "##  Tweets Preprocessing\n",
    "   ###   Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8caf60fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ichristod/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max chars in a tweet: 349\n",
      "max num of words in a tweet: 33\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "df_clean = df.copy(deep=True)\n",
    "\n",
    "# regex to identify URLs\n",
    "regex_url = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
    "# regex to identify mentions\n",
    "regex_mention = r\"@[A-Za-z0-9]+\"\n",
    "# regex to identify hashtags\n",
    "regex_hashtags = r\"#[A-Za-z0-9]+\"\n",
    "# regex to identify punctuations\n",
    "regex_punctuations = r\"[^a-z\\s\\(\\-:\\)\\\\\\/\\];='#]\"\n",
    "# regex to identify numbers\n",
    "regex_numbers = \"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\"\n",
    "# # regex to identify leading & trailing whitespaces\n",
    "regex_whitespaces = \"\\s+\"\n",
    "# set stop words for english language\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "def remove_punctuations(text):\n",
    "    filtered_text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return filtered_text\n",
    "\n",
    "def Find(string):\n",
    "  \n",
    "    # findall() has been used \n",
    "    # with valid conditions for urls in string\n",
    "    regex = r'[^\\w\\s,]'\n",
    "    url = re.findall(regex,string)      \n",
    "    return [x[0] for x in url]\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    list_of_words = [word for word in text.split(' ') if word not in stop_words]\n",
    "    words_to_text = \" \".join(list_of_words)\n",
    "    return words_to_text\n",
    "\n",
    "def clean_text(text):\n",
    "    # transform all tweets to lowercase\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(regex_url, '', text)\n",
    "    text = re.sub(regex_mention, '', text)\n",
    "    text = re.sub(regex_hashtags, '', text)\n",
    "    text = remove_stopwords(text) \n",
    "    text = re.sub(regex_numbers, ' ', text)\n",
    "    text = remove_punctuations(text)\n",
    "    text = re.sub(regex_whitespaces, ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df_clean['tweets'] = df_clean['original_tweets'].apply(clean_text)\n",
    "df_clean['sentiment'] = df_clean['sentiment'].apply(lambda x: x if x<4 else 1)\n",
    "\n",
    "print(\"max chars in a tweet:\",max(len(w) for w in df_clean['tweets']))\n",
    "print(\"max num of words in a tweet:\",max(len(w.split(' ')) for w in df_clean['tweets']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7ef495dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>original_tweets</th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128037</th>\n",
       "      <td>0</td>\n",
       "      <td>Oh really don't wanna be awake</td>\n",
       "      <td>oh really wanna awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491755</th>\n",
       "      <td>0</td>\n",
       "      <td>Trying to amuse my cousin. It's not working! a...</td>\n",
       "      <td>trying amuse cousin working hes playing halo wo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470924</th>\n",
       "      <td>0</td>\n",
       "      <td>@JonasAustralia  i wanted to win! congrats to ...</td>\n",
       "      <td>wanted win congrats anyways</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491263</th>\n",
       "      <td>0</td>\n",
       "      <td>That's it!! I can't take it no more!! After su...</td>\n",
       "      <td>thats it cant take more summer school im talki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836489</th>\n",
       "      <td>1</td>\n",
       "      <td>@beckybootsx i hope your not drinking alcohol!...</td>\n",
       "      <td>hope drinking alcohol lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185199</th>\n",
       "      <td>0</td>\n",
       "      <td>damn iit! I can't believe I left my book at wo...</td>\n",
       "      <td>damn iit cant believe left book work im almost...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870523</th>\n",
       "      <td>1</td>\n",
       "      <td>I'll bake you muffins and make you apricot tea.</td>\n",
       "      <td>ill bake muffins make apricot tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184068</th>\n",
       "      <td>1</td>\n",
       "      <td>Good Afternoon! Starting a class today at chur...</td>\n",
       "      <td>good afternoon starting class today church bus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882071</th>\n",
       "      <td>1</td>\n",
       "      <td>watching lost boys with a margarita</td>\n",
       "      <td>watching lost boys margarita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433855</th>\n",
       "      <td>0</td>\n",
       "      <td>I am way too congested here...head, nose, ear,...</td>\n",
       "      <td>way congested herehead nose ear chestmake stto...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment                                    original_tweets  \\\n",
       "128037           0                    Oh really don't wanna be awake    \n",
       "491755           0  Trying to amuse my cousin. It's not working! a...   \n",
       "470924           0  @JonasAustralia  i wanted to win! congrats to ...   \n",
       "491263           0  That's it!! I can't take it no more!! After su...   \n",
       "836489           1  @beckybootsx i hope your not drinking alcohol!...   \n",
       "...            ...                                                ...   \n",
       "185199           0  damn iit! I can't believe I left my book at wo...   \n",
       "870523           1   I'll bake you muffins and make you apricot tea.    \n",
       "1184068          1  Good Afternoon! Starting a class today at chur...   \n",
       "882071           1               watching lost boys with a margarita    \n",
       "433855           0  I am way too congested here...head, nose, ear,...   \n",
       "\n",
       "                                                    tweets  \n",
       "128037                               oh really wanna awake  \n",
       "491755     trying amuse cousin working hes playing halo wo  \n",
       "470924                         wanted win congrats anyways  \n",
       "491263   thats it cant take more summer school im talki...  \n",
       "836489                           hope drinking alcohol lol  \n",
       "...                                                    ...  \n",
       "185199   damn iit cant believe left book work im almost...  \n",
       "870523                   ill bake muffins make apricot tea  \n",
       "1184068  good afternoon starting class today church bus...  \n",
       "882071                        watching lost boys margarita  \n",
       "433855   way congested herehead nose ear chestmake stto...  \n",
       "\n",
       "[300 rows x 3 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1275af7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>oh really wanna awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>trying amuse cousin working hes playing halo wo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>wanted win congrats anyways</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>thats it cant take more summer school im talki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>hope drinking alcohol lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>0</td>\n",
       "      <td>nk agreemade sad hear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>1</td>\n",
       "      <td>milano awwww cute whats name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>1</td>\n",
       "      <td>hey amazing voice love hair accent please twee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>1</td>\n",
       "      <td>hi sent email prefect blazer hope helps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79999</th>\n",
       "      <td>0</td>\n",
       "      <td>fml work close beauitful dayyyy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                             tweets\n",
       "0              0                              oh really wanna awake\n",
       "1              0    trying amuse cousin working hes playing halo wo\n",
       "2              0                        wanted win congrats anyways\n",
       "3              0  thats it cant take more summer school im talki...\n",
       "4              1                          hope drinking alcohol lol\n",
       "...          ...                                                ...\n",
       "79995          0                              nk agreemade sad hear\n",
       "79996          1                       milano awwww cute whats name\n",
       "79997          1  hey amazing voice love hair accent please twee...\n",
       "79998          1            hi sent email prefect blazer hope helps\n",
       "79999          0                    fml work close beauitful dayyyy\n",
       "\n",
       "[80000 rows x 2 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.drop(['original_tweets'],axis=1,inplace=True)\n",
    "df_clean.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "197b4e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom keras.preprocessing.text import Tokenizer\\nfrom keras.preprocessing.sequence import pad_sequences\\nfrom sklearn.model_selection import train_test_split\\n\\ntokenizer = Tokenizer(num_words=37, split=' ')\\n\\n# create vocabulary based on word frequency\\n#   -word_counts: Dictionary of words and their corresponding counts.\\n#   -word_docs: Dictionary of words and their corresponding documents appeared in.\\n#   -word_index: Dictionary of words and their uniquely assigned integers.\\n#   -document_count: Count of the total number of documents that were used to fit the Tokenizer.\\ntokenizer.fit_on_texts(df_clean['tweets'].values)\\n\\n# texts_to_sequences assigns integers to words for each document\\nX = tokenizer.texts_to_sequences(df_clean['tweets'])\\nY = df_clean['sentiment']\\nX = pad_sequences(X)\\n\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tokenizer = Tokenizer(num_words=37, split=' ')\n",
    "\n",
    "# create vocabulary based on word frequency\n",
    "#   -word_counts: Dictionary of words and their corresponding counts.\n",
    "#   -word_docs: Dictionary of words and their corresponding documents appeared in.\n",
    "#   -word_index: Dictionary of words and their uniquely assigned integers.\n",
    "#   -document_count: Count of the total number of documents that were used to fit the Tokenizer.\n",
    "tokenizer.fit_on_texts(df_clean['tweets'].values)\n",
    "\n",
    "# texts_to_sequences assigns integers to words for each document\n",
    "X = tokenizer.texts_to_sequences(df_clean['tweets'])\n",
    "Y = df_clean['sentiment']\n",
    "X = pad_sequences(X)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "535f7bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define a size for your train set \n",
    "train_size = int(0.6 * len(df_clean))\n",
    "test_size = int(0.2 * len(df_clean))\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "#train_test split\n",
    "X_train = df_clean['tweets'][:train_size]\n",
    "X_test = df_clean['tweets'][train_size:]\n",
    "\n",
    "# Categorically encode labels\n",
    "Y_train = to_categorical(df_clean['sentiment'][:train_size].values, num_classes)\n",
    "Y_test = to_categorical(df_clean['sentiment'][train_size:].values, num_classes)\n",
    "\n",
    "#tokenizer = Tokenizer(num_words=37, split=' ')\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(list(X_train))\n",
    "\n",
    "#converting text into integer sequences\n",
    "X_train_seq  = tokenizer.texts_to_sequences(X_train) \n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "#padding to prepare sequences of same length\n",
    "X_train_seq  = pad_sequences(X_train_seq, maxlen=37)\n",
    "X_test_seq = pad_sequences(X_test_seq, maxlen=37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5811d237",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_17 (Embedding)     (None, 37, 128)           5342336   \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 196)               254800    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 2)                 394       \n",
      "=================================================================\n",
      "Total params: 5,597,530\n",
      "Trainable params: 5,597,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "750/750 [==============================] - 120s 156ms/step - loss: 0.5884 - accuracy: 0.6730 - val_loss: 0.5008 - val_accuracy: 0.7537\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 109s 145ms/step - loss: 0.3817 - accuracy: 0.8309 - val_loss: 0.5358 - val_accuracy: 0.7443\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 103s 137ms/step - loss: 0.2713 - accuracy: 0.8840 - val_loss: 0.5855 - val_accuracy: 0.7368\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 100s 133ms/step - loss: 0.1967 - accuracy: 0.9189 - val_loss: 0.7546 - val_accuracy: 0.7318\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 94s 126ms/step - loss: 0.1414 - accuracy: 0.9412 - val_loss: 0.8491 - val_accuracy: 0.7276\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 99s 133ms/step - loss: 0.1112 - accuracy: 0.9548 - val_loss: 0.9893 - val_accuracy: 0.7231\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 112s 150ms/step - loss: 0.0916 - accuracy: 0.9624 - val_loss: 1.1502 - val_accuracy: 0.7172\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 100s 134ms/step - loss: 0.0757 - accuracy: 0.9688 - val_loss: 1.3515 - val_accuracy: 0.7197\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 101s 135ms/step - loss: 0.0674 - accuracy: 0.9719 - val_loss: 1.3219 - val_accuracy: 0.7117\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 106s 142ms/step - loss: 0.0549 - accuracy: 0.9763 - val_loss: 1.4892 - val_accuracy: 0.7180\n",
      "1000/1000 [==============================] - 14s 13ms/step - loss: 1.4892 - accuracy: 0.7180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4891762733459473, 0.7180312275886536]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "\n",
    "\n",
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size,embed_dim,input_length=37,trainable=True)) \n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(2,activation='sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "Le = LabelEncoder()\n",
    "y = Le.fit_transform(df_clean['sentiment'])\n",
    "model.fit(X_train_seq, Y_train,validation_data = (X_test_seq,Y_test),epochs = 10, batch_size=64)\n",
    "model.evaluate(X_test_seq,Y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
