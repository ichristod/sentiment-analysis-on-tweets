{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e64a5327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>original_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128037</th>\n",
       "      <td>0</td>\n",
       "      <td>Oh really don't wanna be awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491755</th>\n",
       "      <td>0</td>\n",
       "      <td>Trying to amuse my cousin. It's not working! a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470924</th>\n",
       "      <td>0</td>\n",
       "      <td>@JonasAustralia  i wanted to win! congrats to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491263</th>\n",
       "      <td>0</td>\n",
       "      <td>That's it!! I can't take it no more!! After su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836489</th>\n",
       "      <td>4</td>\n",
       "      <td>@beckybootsx i hope your not drinking alcohol!...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentiment                                    original_tweets\n",
       "128037          0                    Oh really don't wanna be awake \n",
       "491755          0  Trying to amuse my cousin. It's not working! a...\n",
       "470924          0  @JonasAustralia  i wanted to win! congrats to ...\n",
       "491263          0  That's it!! I can't take it no more!! After su...\n",
       "836489          4  @beckybootsx i hope your not drinking alcohol!..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from nltk.corpus import stopwords \n",
    "import pandas as pd\n",
    "import numpy as  np\n",
    "import matplotlib as plt\n",
    "import re\n",
    "import string\n",
    "\n",
    "#jupyter path\n",
    "cols = ['sentiment','id','date','query_string','user','original_tweets']\n",
    "df_encoding = \"ISO-8859-1\"\n",
    "df = pd.read_csv(\"training.1600000.processed.noemoticon.csv\",encoding =df_encoding, header=None, names=cols)\n",
    "df.drop(['id','date','query_string','user'],axis=1,inplace=True)\n",
    "df = df.sample(frac=0.05, replace=True, random_state=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b917327d",
   "metadata": {},
   "source": [
    "##  Tweets Preprocessing\n",
    "   ###   Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8caf60fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ichristod/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max chars in a tweet: 317\n",
      "max num of words in a tweet: 33\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "df_clean = df.copy(deep=True)\n",
    "\n",
    "# regex to identify URLs\n",
    "regex_url = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
    "# regex to identify mentions\n",
    "regex_mention = r\"@[A-Za-z0-9]+\"\n",
    "# regex to identify hashtags\n",
    "regex_hashtags = r\"#[A-Za-z0-9]+\"\n",
    "# # regex to identify leading & trailing whitespaces\n",
    "regex_whitespaces = \"\\s+\"\n",
    "# set stop words for english language\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "def remove_punctuations(text):\n",
    "    filtered_text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return filtered_text\n",
    "\n",
    "def Find(string):\n",
    "  \n",
    "    # findall() has been used \n",
    "    # with valid conditions for urls in string\n",
    "    regex = r'[^\\w\\s,]'\n",
    "    url = re.findall(regex,string)      \n",
    "    return [x[0] for x in url]\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    list_of_words = [word for word in text.split(' ') if word not in stop_words]\n",
    "    words_to_text = \" \".join(list_of_words)\n",
    "    return words_to_text\n",
    "\n",
    "def remove_numbers(text):\n",
    "    clear_text = ''.join([i for i in text if not i.isdigit()])\n",
    "    return clear_text\n",
    "\n",
    "def clean_text(text):\n",
    "    # transform all tweets to lowercase\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(regex_url, '', text)\n",
    "    text = re.sub(regex_mention, '', text)\n",
    "    text = re.sub(regex_hashtags, '', text)\n",
    "    text = remove_stopwords(text) \n",
    "    text = remove_punctuations(text)\n",
    "    text = remove_numbers(text)\n",
    "    text = re.sub(regex_whitespaces, ' ', text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "df_clean['tweets'] = df_clean['original_tweets'].apply(clean_text)\n",
    "df_clean['sentiment'] = df_clean['sentiment'].apply(lambda x: x if x<4 else 1)\n",
    "\n",
    "words_length = max(len(w) for w in df_clean['tweets'])\n",
    "sentence_length = max(len(w.split(' ')) for w in df_clean['tweets'])\n",
    "\n",
    "print(\"max chars in a tweet:\", words_length)\n",
    "print(\"max num of words in a tweet:\", sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6e9020b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>original_tweets</th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128037</th>\n",
       "      <td>0</td>\n",
       "      <td>Oh really don't wanna be awake</td>\n",
       "      <td>oh really wanna awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491755</th>\n",
       "      <td>0</td>\n",
       "      <td>Trying to amuse my cousin. It's not working! a...</td>\n",
       "      <td>trying amuse cousin working hes playing halo wo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470924</th>\n",
       "      <td>0</td>\n",
       "      <td>@JonasAustralia  i wanted to win! congrats to ...</td>\n",
       "      <td>wanted win congrats anyways</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491263</th>\n",
       "      <td>0</td>\n",
       "      <td>That's it!! I can't take it no more!! After su...</td>\n",
       "      <td>thats it cant take more summer school im talki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836489</th>\n",
       "      <td>1</td>\n",
       "      <td>@beckybootsx i hope your not drinking alcohol!...</td>\n",
       "      <td>hope drinking alcohol lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053847</th>\n",
       "      <td>1</td>\n",
       "      <td>Breakfast with my mommy</td>\n",
       "      <td>breakfast mommy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992577</th>\n",
       "      <td>1</td>\n",
       "      <td>1 tut down, 123981 projects to go!!</td>\n",
       "      <td>tut down projects go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275825</th>\n",
       "      <td>0</td>\n",
       "      <td>@melody1976 I'm jealous!!  I have 4 weeks to w...</td>\n",
       "      <td>im jealous weeks wait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501507</th>\n",
       "      <td>0</td>\n",
       "      <td>'s heart is aching</td>\n",
       "      <td>s heart aching</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314240</th>\n",
       "      <td>0</td>\n",
       "      <td>just emptied out the bird box, 6 dead baby blu...</td>\n",
       "      <td>emptied bird box dead baby blue tits sad handf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment                                    original_tweets  \\\n",
       "128037           0                    Oh really don't wanna be awake    \n",
       "491755           0  Trying to amuse my cousin. It's not working! a...   \n",
       "470924           0  @JonasAustralia  i wanted to win! congrats to ...   \n",
       "491263           0  That's it!! I can't take it no more!! After su...   \n",
       "836489           1  @beckybootsx i hope your not drinking alcohol!...   \n",
       "...            ...                                                ...   \n",
       "1053847          1                           Breakfast with my mommy    \n",
       "992577           1               1 tut down, 123981 projects to go!!    \n",
       "275825           0  @melody1976 I'm jealous!!  I have 4 weeks to w...   \n",
       "501507           0                                's heart is aching    \n",
       "314240           0  just emptied out the bird box, 6 dead baby blu...   \n",
       "\n",
       "                                                    tweets  \n",
       "128037                               oh really wanna awake  \n",
       "491755     trying amuse cousin working hes playing halo wo  \n",
       "470924                         wanted win congrats anyways  \n",
       "491263   thats it cant take more summer school im talki...  \n",
       "836489                           hope drinking alcohol lol  \n",
       "...                                                    ...  \n",
       "1053847                                    breakfast mommy  \n",
       "992577                                tut down projects go  \n",
       "275825                               im jealous weeks wait  \n",
       "501507                                      s heart aching  \n",
       "314240   emptied bird box dead baby blue tits sad handf...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35706915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>oh really wanna awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>trying amuse cousin working hes playing halo wo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>wanted win congrats anyways</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>thats it cant take more summer school im talki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>hope drinking alcohol lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>0</td>\n",
       "      <td>nk agreemade sad hear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>1</td>\n",
       "      <td>milano awwww cute whats name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>1</td>\n",
       "      <td>hey amazing voice love hair accent please twee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>1</td>\n",
       "      <td>hi sent email prefect blazer hope helps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79999</th>\n",
       "      <td>0</td>\n",
       "      <td>fml work close beauitful dayyyy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                             tweets\n",
       "0              0                              oh really wanna awake\n",
       "1              0    trying amuse cousin working hes playing halo wo\n",
       "2              0                        wanted win congrats anyways\n",
       "3              0  thats it cant take more summer school im talki...\n",
       "4              1                          hope drinking alcohol lol\n",
       "...          ...                                                ...\n",
       "79995          0                              nk agreemade sad hear\n",
       "79996          1                       milano awwww cute whats name\n",
       "79997          1  hey amazing voice love hair accent please twee...\n",
       "79998          1            hi sent email prefect blazer hope helps\n",
       "79999          0                    fml work close beauitful dayyyy\n",
       "\n",
       "[80000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.drop(['original_tweets'],axis=1,inplace=True)\n",
    "df_clean.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f32f94bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# Define a size for your train set \n",
    "train_size = int(0.6 * len(df_clean))\n",
    "validation_size = int(0.2 * len(df_clean))\n",
    "test_size = int(0.2 * len(df_clean))\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "#train_test split\n",
    "X_train = df_clean['tweets'][:train_size]\n",
    "X_validation = df_clean['tweets'][train_size:]\n",
    "X_test = df_clean['tweets'][train_size:]\n",
    "\n",
    "# Categorically encode labels\n",
    "Y_train = to_categorical(df_clean['sentiment'][:train_size].values, num_classes)\n",
    "Y_test = to_categorical(df_clean['sentiment'][train_size:].values, num_classes)\n",
    "\n",
    "# create vocabulary based on word frequency\n",
    "#   -word_counts: Dictionary of words and their corresponding counts.\n",
    "#   -word_docs: Dictionary of words and their corresponding documents appeared in.\n",
    "#   -word_index: Dictionary of words and their uniquely assigned integers.\n",
    "#   -document_count: Count of the total number of documents that were used to fit the Tokenizer.\n",
    "tokenizer_train = Tokenizer()\n",
    "tokenizer_test = Tokenizer()\n",
    "tokenizer_train.fit_on_texts(list(X_train))\n",
    "tokenizer_test.fit_on_texts(list(X_test))\n",
    "\n",
    "# texts_to_sequences assigns integers to words for each document\n",
    "X_train_seq  = tokenizer_train.texts_to_sequences(X_train) \n",
    "X_test_seq = tokenizer_test.texts_to_sequences(X_test)\n",
    "\n",
    "# padding to prepare sequences of same length\n",
    "X_train_seq  = pad_sequences(X_train_seq, maxlen=sentence_length)\n",
    "X_test_seq = pad_sequences(X_test_seq, maxlen=sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30e20dd6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 33, 128)           5151488   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 512)               788480    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 6,203,650\n",
      "Trainable params: 6,203,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "375/375 [==============================] - 163s 419ms/step - loss: 0.5900 - accuracy: 0.6646 - val_loss: 0.8654 - val_accuracy: 0.5243\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 144s 383ms/step - loss: 0.3884 - accuracy: 0.8302 - val_loss: 1.0178 - val_accuracy: 0.5178\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 151s 402ms/step - loss: 0.2691 - accuracy: 0.8884 - val_loss: 1.3297 - val_accuracy: 0.5116\n",
      "Epoch 4/10\n",
      "127/375 [=========>....................] - ETA: 1:24 - loss: 0.1788 - accuracy: 0.9297"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-6c29cb89ab14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mLe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test_seq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_seq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sentimentAnalysis/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sentimentAnalysis/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sentimentAnalysis/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sentimentAnalysis/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sentimentAnalysis/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniconda3/envs/sentimentAnalysis/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sentimentAnalysis/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "\n",
    "\n",
    "embed_dim = 128\n",
    "lstm_out = 256\n",
    "vocab_size = max(len(tokenizer_train.word_index),len(tokenizer_train.word_index))+1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size,embed_dim,input_length=sentence_length,trainable=True)) \n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(2,activation='sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "Le = LabelEncoder()\n",
    "y = Le.fit_transform(df_clean['sentiment'])\n",
    "model.fit(X_train_seq, Y_train,validation_data = (X_test_seq,Y_test),epochs = 10, batch_size=128)\n",
    "model.evaluate(X_test_seq,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4981b48c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
