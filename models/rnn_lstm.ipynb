{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e64a5327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>original_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128037</th>\n",
       "      <td>0</td>\n",
       "      <td>Oh really don't wanna be awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491755</th>\n",
       "      <td>0</td>\n",
       "      <td>Trying to amuse my cousin. It's not working! a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470924</th>\n",
       "      <td>0</td>\n",
       "      <td>@JonasAustralia  i wanted to win! congrats to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491263</th>\n",
       "      <td>0</td>\n",
       "      <td>That's it!! I can't take it no more!! After su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836489</th>\n",
       "      <td>4</td>\n",
       "      <td>@beckybootsx i hope your not drinking alcohol!...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentiment                                    original_tweets\n",
       "128037          0                    Oh really don't wanna be awake \n",
       "491755          0  Trying to amuse my cousin. It's not working! a...\n",
       "470924          0  @JonasAustralia  i wanted to win! congrats to ...\n",
       "491263          0  That's it!! I can't take it no more!! After su...\n",
       "836489          4  @beckybootsx i hope your not drinking alcohol!..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from nltk.corpus import stopwords \n",
    "import pandas as pd\n",
    "import numpy as  np\n",
    "import matplotlib as plt\n",
    "import re\n",
    "import string\n",
    "\n",
    "#jupyter path\n",
    "cols = ['sentiment','id','date','query_string','user','original_tweets']\n",
    "df_encoding = \"ISO-8859-1\"\n",
    "df = pd.read_csv(\"training.1600000.processed.noemoticon.csv\",encoding =df_encoding, header=None, names=cols)\n",
    "df.drop(['id','date','query_string','user'],axis=1,inplace=True)\n",
    "df = df.sample(frac=0.05, replace=True, random_state=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814c9332",
   "metadata": {},
   "source": [
    "## Define usefull functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8caf60fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ichristod/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "# set stop words for english language\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    filtered_text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return filtered_text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    list_of_words = [word for word in text.split(' ') if word not in stop_words]\n",
    "    words_to_text = \" \".join(list_of_words)\n",
    "    return words_to_text\n",
    "\n",
    "def remove_numbers(text):\n",
    "    clear_text = ''.join([i for i in text if not i.isdigit()])\n",
    "    return clear_text\n",
    "\n",
    "def clean_text(text):    \n",
    "    # regex dictionary\n",
    "    regex = {\n",
    "        \"urls\": r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\",\n",
    "        \"mentions\": r\"@[A-Za-z0-9]+\",\n",
    "        \"hashtags\": r\"#[A-Za-z0-9]+\",\n",
    "        \"whitespaces\": \"\\s+\"\n",
    "    }\n",
    "    \n",
    "    text = str(text).lower()\n",
    "    text = re.sub(regex['urls'], '', text)\n",
    "    text = re.sub(regex['mentions'], '', text)\n",
    "    text = re.sub(regex['hashtags'], '', text)\n",
    "    text = remove_stopwords(text) \n",
    "    text = remove_punctuations(text)\n",
    "    text = remove_numbers(text)\n",
    "    text = re.sub(regex['whitespaces'], ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def create_subsets(dataset, features, labels, num_classes, train_size=0, valid_size=0, test_size=0):\n",
    "    subsets = {}\n",
    "    \n",
    "    # Define a size for your train set \n",
    "    train_n = int(train_size * len(dataset))\n",
    "    valid_n = int(valid_size * len(dataset))\n",
    "    test_n = int(test_size * len(dataset))\n",
    "    \n",
    "    #train_test split\n",
    "    subsets['X_train'] = dataset[features][:train_n]\n",
    "    subsets['X_valid'] = dataset[features][train_n:train_n+valid_n]\n",
    "    subsets['X_test'] = dataset[features][train_n+valid_n:train_n+valid_n+test_n]\n",
    "\n",
    "    # Categorically encode labels\n",
    "    subsets['Y_train'] = to_categorical(dataset[labels][:train_n].values, num_classes)\n",
    "    subsets['Y_valid'] = to_categorical(dataset[labels][train_n:train_n+valid_n].values, num_classes)\n",
    "    subsets['Y_test'] = to_categorical(dataset[labels][train_n:].values, num_classes)\n",
    "    return subsets\n",
    "\n",
    "def words_to_sequences(max_sentence_length, subsets):\n",
    "    seq_subsets = {}\n",
    "    vocab_size = 0\n",
    "    for key, value in subsets.items():\n",
    "        if key.startswith('X'):\n",
    "            # create vocabulary based on word frequency\n",
    "            #   -word_counts: Dictionary of words and their corresponding counts.\n",
    "            #   -word_docs: Dictionary of words and their corresponding documents appeared in.\n",
    "            #   -word_index: Dictionary of words and their uniquely assigned integers.\n",
    "            #   -document_count: Count of the total number of documents that were used to fit the Tokenizer.\n",
    "            tokenizer = Tokenizer()\n",
    "            tokenizer.fit_on_texts(list(value))\n",
    "            # texts_to_sequences assigns integers to words for each document\n",
    "            sequence = tokenizer.texts_to_sequences(value)\n",
    "            # padding to prepare sequences of same length\n",
    "            sequence = pad_sequences(sequence, maxlen = max_sentence_length)\n",
    "            seq_subsets[key] = sequence\n",
    "            \n",
    "            if len(tokenizer.word_index) > vocab_size:\n",
    "                vocab_size = len(tokenizer.word_index)\n",
    "\n",
    "    return seq_subsets, vocab_size+1;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b696f55d",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16f19d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max chars in a tweet: 317\n",
      "max num of words in a tweet: 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>original_tweets</th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128037</th>\n",
       "      <td>0</td>\n",
       "      <td>Oh really don't wanna be awake</td>\n",
       "      <td>oh really wanna awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491755</th>\n",
       "      <td>0</td>\n",
       "      <td>Trying to amuse my cousin. It's not working! a...</td>\n",
       "      <td>trying amuse cousin working hes playing halo wo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470924</th>\n",
       "      <td>0</td>\n",
       "      <td>@JonasAustralia  i wanted to win! congrats to ...</td>\n",
       "      <td>wanted win congrats anyways</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491263</th>\n",
       "      <td>0</td>\n",
       "      <td>That's it!! I can't take it no more!! After su...</td>\n",
       "      <td>thats it cant take more summer school im talki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836489</th>\n",
       "      <td>1</td>\n",
       "      <td>@beckybootsx i hope your not drinking alcohol!...</td>\n",
       "      <td>hope drinking alcohol lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053847</th>\n",
       "      <td>1</td>\n",
       "      <td>Breakfast with my mommy</td>\n",
       "      <td>breakfast mommy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992577</th>\n",
       "      <td>1</td>\n",
       "      <td>1 tut down, 123981 projects to go!!</td>\n",
       "      <td>tut down projects go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275825</th>\n",
       "      <td>0</td>\n",
       "      <td>@melody1976 I'm jealous!!  I have 4 weeks to w...</td>\n",
       "      <td>im jealous weeks wait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501507</th>\n",
       "      <td>0</td>\n",
       "      <td>'s heart is aching</td>\n",
       "      <td>s heart aching</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314240</th>\n",
       "      <td>0</td>\n",
       "      <td>just emptied out the bird box, 6 dead baby blu...</td>\n",
       "      <td>emptied bird box dead baby blue tits sad handf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment                                    original_tweets  \\\n",
       "128037           0                    Oh really don't wanna be awake    \n",
       "491755           0  Trying to amuse my cousin. It's not working! a...   \n",
       "470924           0  @JonasAustralia  i wanted to win! congrats to ...   \n",
       "491263           0  That's it!! I can't take it no more!! After su...   \n",
       "836489           1  @beckybootsx i hope your not drinking alcohol!...   \n",
       "...            ...                                                ...   \n",
       "1053847          1                           Breakfast with my mommy    \n",
       "992577           1               1 tut down, 123981 projects to go!!    \n",
       "275825           0  @melody1976 I'm jealous!!  I have 4 weeks to w...   \n",
       "501507           0                                's heart is aching    \n",
       "314240           0  just emptied out the bird box, 6 dead baby blu...   \n",
       "\n",
       "                                                    tweets  \n",
       "128037                               oh really wanna awake  \n",
       "491755     trying amuse cousin working hes playing halo wo  \n",
       "470924                         wanted win congrats anyways  \n",
       "491263   thats it cant take more summer school im talki...  \n",
       "836489                           hope drinking alcohol lol  \n",
       "...                                                    ...  \n",
       "1053847                                    breakfast mommy  \n",
       "992577                                tut down projects go  \n",
       "275825                               im jealous weeks wait  \n",
       "501507                                      s heart aching  \n",
       "314240   emptied bird box dead baby blue tits sad handf...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy dataframe\n",
    "df_clean = df.copy(deep=True)\n",
    "\n",
    "# clean text\n",
    "df_clean['tweets'] = df_clean['original_tweets'].apply(clean_text)\n",
    "\n",
    "# transform labels\n",
    "df_clean['sentiment'] = df_clean['sentiment'].apply(lambda x: x if x<4 else 1)\n",
    "\n",
    "# keep max length of words and sentences\n",
    "words_length = max(len(w) for w in df_clean['tweets'])\n",
    "sentence_length = max(len(w.split(' ')) for w in df_clean['tweets'])\n",
    "\n",
    "print(\"max chars in a tweet:\", words_length)\n",
    "print(\"max num of words in a tweet:\", sentence_length)\n",
    "\n",
    "df_clean.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e43f00a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>oh really wanna awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>trying amuse cousin working hes playing halo wo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>wanted win congrats anyways</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>thats it cant take more summer school im talki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>hope drinking alcohol lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>0</td>\n",
       "      <td>nk agreemade sad hear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>1</td>\n",
       "      <td>milano awwww cute whats name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>1</td>\n",
       "      <td>hey amazing voice love hair accent please twee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>1</td>\n",
       "      <td>hi sent email prefect blazer hope helps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79999</th>\n",
       "      <td>0</td>\n",
       "      <td>fml work close beauitful dayyyy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                             tweets\n",
       "0              0                              oh really wanna awake\n",
       "1              0    trying amuse cousin working hes playing halo wo\n",
       "2              0                        wanted win congrats anyways\n",
       "3              0  thats it cant take more summer school im talki...\n",
       "4              1                          hope drinking alcohol lol\n",
       "...          ...                                                ...\n",
       "79995          0                              nk agreemade sad hear\n",
       "79996          1                       milano awwww cute whats name\n",
       "79997          1  hey amazing voice love hair accent please twee...\n",
       "79998          1            hi sent email prefect blazer hope helps\n",
       "79999          0                    fml work close beauitful dayyyy\n",
       "\n",
       "[80000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove necessary columns & reset indexes\n",
    "df_clean.drop(['original_tweets'],axis=1,inplace=True)\n",
    "df_clean.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc1e56b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from collections import defaultdict\n",
    "\n",
    "features = 'tweets'\n",
    "labels = 'sentiment'\n",
    "\n",
    "#create appropriate subsets\n",
    "initial_subsets = create_subsets(dataset=df_clean, features=features, labels=labels, \n",
    "                   train_size=0.6, valid_size=0.2, test_size=0.2, num_classes=2)\n",
    "\n",
    "# convert features (text) to sequences\n",
    "seq_subsets, vocab_size = words_to_sequences(sentence_length, subsets=initial_subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a10be0d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 33, 128)           5151488   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 5,546,242\n",
      "Trainable params: 5,546,242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "\n",
    "\n",
    "embed_dim = 128\n",
    "lstm_out = 256\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size,embed_dim,input_length=sentence_length,trainable=True)) \n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(2,activation='sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "Le = LabelEncoder()\n",
    "y = Le.fit_transform(df_clean['sentiment'])\n",
    "model.fit(seq_subsets['X_train'], initial_subsets['Y_train'],validation_data = (seq_subsets['X_valid'],initial_subsets['Y_valid']),epochs = 10, batch_size=128)\n",
    "model.evaluate(seq_subsets['X_test'],initial_subsets['Y_test'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
